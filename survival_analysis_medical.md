# Survival Analysis in Medicine and Biology
## When Time-to-Event Matters More Than Binary Outcomes

### Intent
Survival analysis handles time-to-event data with censoring‚Äîwhen we observe some but not all event times. Critical for clinical trials, disease progression, and biological processes where timing carries mechanistic information that binary outcomes discard.

### Mathematical Foundation

#### Core Concepts

**Survival Function:** S(t) = P(T > t) = probability of surviving past time t

**Hazard Function:** h(t) = lim_{Œît‚Üí0} P(t ‚â§ T < t+Œît | T ‚â• t)/Œît
- Instantaneous risk of event at time t, given survival until t
- h(t) = f(t)/S(t) = -d[log S(t)]/dt

**Cumulative Hazard:** H(t) = ‚à´‚ÇÄ·µó h(u)du = -log S(t)

**Fundamental Relationship:**
```
S(t) = exp(-H(t)) = exp(-‚à´‚ÇÄ·µó h(u)du)
```

#### The Censoring Problem

Dataset: {(T·µ¢, Œ¥·µ¢, X·µ¢)}‚Åø·µ¢‚Çå‚ÇÅ where:
- T·µ¢ = min(T*·µ¢, C·µ¢) observed time
- T*·µ¢ = true event time
- C·µ¢ = censoring time
- Œ¥·µ¢ = ùüô[T*·µ¢ ‚â§ C·µ¢] event indicator
- X·µ¢ = covariates

**Types of Censoring:**
1. **Right censoring:** Event hasn't occurred by study end
2. **Left censoring:** Event occurred before observation began
3. **Interval censoring:** Event occurred between observations
4. **Informative censoring:** Censoring related to outcome (violates assumptions)

### Core Methods

#### 1. Kaplan-Meier Estimator (Non-parametric)

**Formulation:**
```
≈ú(t) = ‚àè_{t‚±º‚â§t} (1 - d‚±º/n‚±º)

where:
- t‚±º: ordered unique event times
- d‚±º: number of events at t‚±º
- n‚±º: number at risk just before t‚±º
```

**Variance (Greenwood's formula):**
```
Var[≈ú(t)] = ≈ú(t)¬≤ √ó Œ£_{t‚±º‚â§t} [d‚±º/(n‚±º(n‚±º-d‚±º))]
```

**Confidence Intervals (log-log transformation for boundedness):**
```
CI = exp{¬±z_{Œ±/2} √ó ‚àöVar[log(-log ≈ú(t))]}
```

#### 2. Cox Proportional Hazards Model (Semi-parametric)

**Model:**
```
h(t|X) = h‚ÇÄ(t) √ó exp(X^T Œ≤)

where:
- h‚ÇÄ(t): baseline hazard (unspecified)
- exp(X^T Œ≤): relative hazard
```

**Partial Likelihood (Cox, 1975):**
```
L(Œ≤) = ‚àè·µ¢:Œ¥·µ¢=1 [exp(X·µ¢^T Œ≤) / Œ£_{j‚ààR(t·µ¢)} exp(X‚±º^T Œ≤)]

where R(t) = {j: T‚±º ‚â• t} is the risk set
```

**No need to specify h‚ÇÄ(t)!** This is the key innovation.

**Parameter Estimation:**
```python
# Newton-Raphson for Œ≤
Œ≤_new = Œ≤_old + I(Œ≤_old)‚Åª¬π √ó U(Œ≤_old)

where:
U(Œ≤) = ‚àÇlog L/‚àÇŒ≤  # Score function
I(Œ≤) = -‚àÇ¬≤log L/‚àÇŒ≤‚àÇŒ≤^T  # Information matrix
```

#### 3. Accelerated Failure Time Models (Parametric)

**Model:** log T = X^T Œ≤ + œÉŒµ

**Common Distributions:**

| Distribution | Hazard Shape | Use Case | Survival Function |
|--------------|--------------|----------|-------------------|
| **Exponential** | Constant | Memoryless processes | S(t) = exp(-Œªt) |
| **Weibull** | Monotonic | Aging/wear processes | S(t) = exp(-(t/Œª)^k) |
| **Log-normal** | Non-monotonic | Biological growth | S(t) = 1 - Œ¶(log(t)-Œº)/œÉ) |
| **Log-logistic** | Non-monotonic | Immunological response | S(t) = 1/(1+(t/Œ±)^Œ≤) |

**Parameter interpretation:**
- Cox: exp(Œ≤) = hazard ratio
- AFT: exp(Œ≤) = time ratio (acceleration factor)

### Assumptions & Diagnostics

#### 1. Proportional Hazards Assumption (Cox Model)

**Mathematical Statement:** h‚ÇÅ(t)/h‚ÇÇ(t) = constant over time

**Schoenfeld Residuals Test:**
```python
def test_proportional_hazards(cox_model, data):
    """
    H‚ÇÄ: Œ≤(t) = Œ≤ (constant over time)
    """
    residuals = cox_model.compute_schoenfeld_residuals()
    
    for covariate in covariates:
        # Residuals should have zero slope over time
        correlation = spearmanr(residuals[covariate], event_times)
        p_value = correlation.pvalue
        
        if p_value < 0.05:
            print(f"{covariate} violates PH assumption")
            
    # Visual check
    plot_schoenfeld(residuals, transform='km')  # Should be horizontal
```

**Solutions for PH Violations:**
1. **Stratification:** h(t|X, stratum=s) = h‚ÇÄ‚Çõ(t) √ó exp(X^T Œ≤)
2. **Time-varying coefficients:** Œ≤(t) = Œ≤‚ÇÄ + Œ≤‚ÇÅ √ó g(t)
3. **Time-dependent covariates:** X(t)

#### 2. Independent Censoring Assumption

**Requirement:** P(C > t | T* = s, X) = P(C > t | X) for all s, t

**Violations & Solutions:**

| Scenario | Problem | Solution |
|----------|---------|----------|
| **Competing risks** | Death from other causes | Cause-specific or subdistribution hazards |
| **Dependent censoring** | Sicker patients drop out | Inverse probability weighting |
| **Cure fraction** | Subset never experiences event | Mixture cure models |

### Advanced Methods for Complex Biology

#### 1. Time-Dependent Covariates

**Extended Cox Model:**
```
h(t|X(t)) = h‚ÇÄ(t) √ó exp[Œ£‚±º Œ≤‚±ºX‚±º(t)]
```

**Implementation Challenges:**
```python
# Data structure: Start-stop format
# Each row represents an interval for one subject
data_extended = [
    (id=1, tstart=0,  tstop=30, X_bp=120, event=0),
    (id=1, tstart=30, tstop=65, X_bp=140, event=1),
    # ...
]

# Partial likelihood modification
L(Œ≤) = ‚àè·µ¢:Œ¥·µ¢=1 [exp(X·µ¢(t·µ¢)^T Œ≤) / Œ£_{j‚ààR(t·µ¢)} exp(X‚±º(t·µ¢)^T Œ≤)]
```

#### 2. Competing Risks

**Cause-Specific Hazard:**
```
h_k(t) = lim_{Œît‚Üí0} P(t ‚â§ T < t+Œît, cause=k | T ‚â• t)/Œît
```

**Cumulative Incidence Function:**
```
CIF_k(t) = P(T ‚â§ t, cause=k) = ‚à´‚ÇÄ·µó S(u) √ó h_k(u) du

where S(t) = exp(-Œ£‚Çñ H_k(t))
```

**Fine-Gray Model (Subdistribution hazard):**
```
h*_k(t) = lim_{Œît‚Üí0} P(t ‚â§ T < t+Œît, cause=k | T ‚â• t or (T < t and cause ‚â† k))/Œît
```

#### 3. Recurrent Events

**Counting Process Formulation:**
```
N(t) = number of events by time t
dN(t) = N(t) - N(t‚Åª)

Intensity: Œª(t) = E[dN(t) | history]
```

**Models:**
- **Andersen-Gill:** All events contribute equally
- **Prentice-Williams-Peterson:** Risk set changes after each event
- **Wei-Lin-Weissfeld:** Marginal model for ordered events

#### 4. Joint Models for Longitudinal and Survival Data

**Application:** Biomarker trajectory affects survival

```
Longitudinal: Y_i(t) = X_i(t)^T Œ≤ + Z_i(t)^T b_i + Œµ_i(t)
Survival: h_i(t) = h‚ÇÄ(t) √ó exp(W_i^T Œ≥ + Œ±f(Y_i(t)))

where f(¬∑) links biomarker to hazard
```

### Medical Applications & Pitfalls

| Clinical Context | Key Considerations | Common Errors |
|-----------------|-------------------|---------------|
| **Cancer trials** | Delayed treatment effect | Using logrank when hazards cross |
| **Cardiovascular** | Multiple events (MI, stroke, death) | Ignoring recurrent events |
| **Transplantation** | Time-dependent exposure | Immortal time bias |
| **Infectious disease** | Cure fraction | Standard Cox assumes everyone susceptible |
| **Pharmacokinetics** | Interval censoring | Treating as right-censored |
| **Genetic studies** | Age-dependent penetrance | Not accounting for ascertainment |

### Sample Size Calculation

**Logrank Test Power:**
```python
def sample_size_survival(hr, p_event_control, alpha=0.05, power=0.8, ratio=1):
    """
    Schoenfeld formula for Cox/logrank
    
    hr: hazard ratio
    p_event_control: probability of event in control
    ratio: allocation ratio (treatment:control)
    """
    z_alpha = norm.ppf(1 - alpha/2)
    z_beta = norm.ppf(power)
    
    # Number of events needed
    d = ((z_alpha + z_beta)**2 * (1 + ratio)**2) / (ratio * log(hr)**2)
    
    # Total sample size
    n = d / (p_event_control * (1 + ratio*hr)/(1 + ratio))
    
    return ceil(n)
```

**Accounting for Censoring:**
```
n_adjusted = n / (1 - dropout_rate)
```

### Implementation Template

```python
class ClinicalSurvivalAnalysis:
    """Complete survival analysis pipeline for clinical data"""
    
    def __init__(self, data, time_col, event_col, covariate_cols):
        self.data = data
        self.time = time_col
        self.event = event_col
        self.covariates = covariate_cols
        
    def exploratory_analysis(self):
        """Initial exploration"""
        # 1. Censoring proportion
        censoring_rate = 1 - self.data[self.event].mean()
        
        # 2. Follow-up time distribution
        median_followup = self.data.loc[
            self.data[self.event] == 0, self.time
        ].median()
        
        # 3. Event time distribution
        km_fit = KaplanMeierFitter()
        km_fit.fit(self.data[self.time], self.data[self.event])
        median_survival = km_fit.median_survival_time_
        
        return {
            'censoring_rate': censoring_rate,
            'median_followup': median_followup,
            'median_survival': median_survival
        }
    
    def fit_models(self):
        """Fit hierarchy of models"""
        results = {}
        
        # 1. Non-parametric (Kaplan-Meier)
        km = KaplanMeierFitter()
        km.fit(self.data[self.time], self.data[self.event])
        results['km'] = km
        
        # 2. Semi-parametric (Cox)
        cox = CoxPHFitter()
        cox.fit(self.data[[self.time, self.event] + self.covariates],
                self.time, self.event)
        results['cox'] = cox
        
        # 3. Test proportional hazards
        ph_test = proportional_hazard_test(cox, self.data)
        if ph_test.p_value < 0.05:
            # Use stratified Cox or time-varying
            cox_strat = CoxPHFitter()
            cox_strat.fit(..., strata=problematic_vars)
            results['cox_stratified'] = cox_strat
        
        # 4. Parametric alternatives
        for dist_name in ['weibull', 'lognormal', 'loglogistic']:
            aft = ParametricSurvival(dist_name)
            aft.fit(self.data)
            results[f'aft_{dist_name}'] = aft
            
        return results
    
    def validate_model(self, model, method='bootstrap', n_iterations=100):
        """Internal validation"""
        if method == 'bootstrap':
            c_indices = []
            for _ in range(n_iterations):
                boot_idx = np.random.choice(len(self.data), len(self.data))
                boot_data = self.data.iloc[boot_idx]
                
                model_boot = model.__class__()
                model_boot.fit(boot_data)
                c_indices.append(model_boot.concordance_index_)
            
            return {
                'c_index_mean': np.mean(c_indices),
                'c_index_std': np.std(c_indices),
                'optimism': model.concordance_index_ - np.mean(c_indices)
            }
    
    def clinical_predictions(self, model, times=[1, 3, 5]):
        """Clinically relevant predictions"""
        predictions = {}
        
        for t in times:
            # Survival probability at time t
            predictions[f'{t}yr_survival'] = model.predict_survival_function(
                self.data[self.covariates], times=[t*365]
            )
            
            # Risk stratification
            risk_scores = model.predict_partial_hazard(self.data[self.covariates])
            tertiles = pd.qcut(risk_scores, 3, labels=['Low', 'Medium', 'High'])
            predictions[f'{t}yr_risk_groups'] = tertiles
            
        return predictions
```

### Reporting Guidelines

**Essential Elements (per STROBE):**
- [ ] Number at risk at key timepoints
- [ ] Median follow-up time
- [ ] Censoring proportion and pattern
- [ ] Survival curve with confidence bands
- [ ] Number of events per covariate (‚â•10 rule)
- [ ] Assumption checks (PH, linearity)
- [ ] Handling of missing data
- [ ] Sensitivity analyses

**Advanced Reporting:**
- [ ] Time-dependent ROC/AUC
- [ ] Calibration plots
- [ ] Decision curve analysis
- [ ] Restricted mean survival time
- [ ] Life-years gained

### References
- Cox, D.R. (1972). Regression models and life-tables
- Therneau, T.M. & Grambsch, P.M. (2000). Modeling Survival Data
- Royston, P. & Parmar, M.K. (2013). Restricted mean survival time
- Putter, H. et al. (2007). Tutorial in biostatistics: competing risks and multi-state models